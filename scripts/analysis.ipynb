{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from scipy.stats import pointbiserialr\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Unifying Words Count</th>\n",
       "      <th>Polarizing Words Count</th>\n",
       "      <th>Total Words Count</th>\n",
       "      <th>Political Party</th>\n",
       "      <th>Overall Language</th>\n",
       "      <th>Unifying Words Ratio</th>\n",
       "      <th>Polarizing Words Ratio</th>\n",
       "      <th>Overall Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump (2nd Term)</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2905</td>\n",
       "      <td>Republican</td>\n",
       "      <td>polarizing</td>\n",
       "      <td>0.00723</td>\n",
       "      <td>0.00757</td>\n",
       "      <td>0.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph R. Biden, Jr.</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>2532</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.01145</td>\n",
       "      <td>0.00434</td>\n",
       "      <td>2.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald J. Trump (1st Term)</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1455</td>\n",
       "      <td>Republican</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00687</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>2.4982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2090</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.00239</td>\n",
       "      <td>3.2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>2391</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>polarizing</td>\n",
       "      <td>0.00627</td>\n",
       "      <td>0.00753</td>\n",
       "      <td>0.8327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Unifying Words Count  Polarizing Words Count  \\\n",
       "0  Donald J. Trump (2nd Term)                    21                      22   \n",
       "1        Joseph R. Biden, Jr.                    29                      11   \n",
       "2  Donald J. Trump (1st Term)                    10                       4   \n",
       "3                Barack Obama                    16                       5   \n",
       "4                Barack Obama                    15                      18   \n",
       "\n",
       "   Total Words Count Political Party Overall Language  Unifying Words Ratio  \\\n",
       "0               2905      Republican       polarizing               0.00723   \n",
       "1               2532        Democrat         unifying               0.01145   \n",
       "2               1455      Republican         unifying               0.00687   \n",
       "3               2090        Democrat         unifying               0.00766   \n",
       "4               2391        Democrat       polarizing               0.00627   \n",
       "\n",
       "   Polarizing Words Ratio  Overall Ratio  \n",
       "0                 0.00757         0.9551  \n",
       "1                 0.00434         2.6382  \n",
       "2                 0.00275         2.4982  \n",
       "3                 0.00239         3.2050  \n",
       "4                 0.00753         0.8327  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_dir = Path.cwd()\n",
    "file_path = notebook_dir.parent / \"data\" / \"speech_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Subset data with Republican or Democratic Presidents \n",
    "df2 = df[(df[\"Political Party\"] == \"Republican\")|(df[\"Political Party\"] == \"Democrat\")].copy()\n",
    "\n",
    "df2[\"Political Party\"].unique()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Unifying Words Count</th>\n",
       "      <th>Polarizing Words Count</th>\n",
       "      <th>Total Words Count</th>\n",
       "      <th>Political Party</th>\n",
       "      <th>Overall Language</th>\n",
       "      <th>Unifying Words Ratio</th>\n",
       "      <th>Polarizing Words Ratio</th>\n",
       "      <th>Overall Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump (2nd Term)</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2905</td>\n",
       "      <td>0</td>\n",
       "      <td>polarizing</td>\n",
       "      <td>0.00723</td>\n",
       "      <td>0.00757</td>\n",
       "      <td>0.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph R. Biden, Jr.</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>2532</td>\n",
       "      <td>1</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.01145</td>\n",
       "      <td>0.00434</td>\n",
       "      <td>2.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald J. Trump (1st Term)</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1455</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00687</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>2.4982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Unifying Words Count  Polarizing Words Count  \\\n",
       "0  Donald J. Trump (2nd Term)                    21                      22   \n",
       "1        Joseph R. Biden, Jr.                    29                      11   \n",
       "2  Donald J. Trump (1st Term)                    10                       4   \n",
       "\n",
       "   Total Words Count  Political Party Overall Language  Unifying Words Ratio  \\\n",
       "0               2905                0       polarizing               0.00723   \n",
       "1               2532                1         unifying               0.01145   \n",
       "2               1455                0         unifying               0.00687   \n",
       "\n",
       "   Polarizing Words Ratio  Overall Ratio  \n",
       "0                 0.00757         0.9551  \n",
       "1                 0.00434         2.6382  \n",
       "2                 0.00275         2.4982  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode Political Party as a binary variable for point biserial correlation analysis \n",
    "\n",
    "df2['Political Party'] = df2['Political Party'].map({'Republican': 0, 'Democrat': 1})\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis I: Using all presidential speech data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Biserial Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.05972\n",
      "p-value: 0.68036\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pointbiserialr(df2['Political Party'], df2['Overall Ratio'])\n",
    "\n",
    "print(\"Correlation:\", round(correlation, 5))\n",
    "print(\"p-value:\", round(p_value, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not yield very statistically significant results nor any strong relationship between political party and primary type of language used. Let's try some other methods..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.4\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3 2]\n",
      " [4 1]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.60      0.50         5\n",
      "           1       0.33      0.20      0.25         5\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.38      0.40      0.38        10\n",
      "weighted avg       0.38      0.40      0.38        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature and target selection\n",
    "X = df2.drop(columns=[\"Political Party\", \"Name\", \"Overall Language\"]) # X = df2[[\"Political Party\"]]\n",
    "y = df2[\"Political Party\"]\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on train data and transform\n",
    "X_test = scaler.transform(X_test)  # Only transform test data\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# print(\"Training Accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance for Logistic Regression:\n",
      "                  Feature  Coefficient\n",
      "0    Unifying Words Count     0.312664\n",
      "1  Polarizing Words Count    -0.300659\n",
      "2       Total Words Count    -0.461904\n",
      "3    Unifying Words Ratio     0.183516\n",
      "4  Polarizing Words Ratio     0.978647\n",
      "5           Overall Ratio     0.486419\n"
     ]
    }
   ],
   "source": [
    "# Extract feature coefficients\n",
    "coefficients = model.coef_[0]\n",
    "features = X.columns  # Fix: Use X instead of X_train to get feature names\n",
    "\n",
    "# Create a DataFrame for better readability\n",
    "feature_importance = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
    "# feature_importance['Absolute Coefficient'] = np.abs(feature_importance['Coefficient'])\n",
    "# feature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "print(\"Feature Importance for Logistic Regression:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model with Strongest Features: Unifying Words Count, Polarizing Words Count, and Overall Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.4\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2 3]\n",
      " [3 2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.40      0.40      0.40         5\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.40      0.40      0.40        10\n",
      "weighted avg       0.40      0.40      0.40        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature and target selection\n",
    "X = df2[[\"Polarizing Words Ratio\", \"Overall Ratio\", \"Total Words Count\"]] \n",
    "y = df2[\"Political Party\"]\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on train data and transform\n",
    "X_test = scaler.transform(X_test)  # Only transform test data\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4002, stratify=y)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# print(\"Training Accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy is higher fitting a model with only the strongest features, but precision, recall, and F1-score are 0 for Democratic party classifications, so we'll use the logistic regression model with all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis II: Using only 'modern' data \n",
    "We define modern presidential speech data as presidents after Richard Nixon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Unifying Words Count</th>\n",
       "      <th>Polarizing Words Count</th>\n",
       "      <th>Total Words Count</th>\n",
       "      <th>Political Party</th>\n",
       "      <th>Overall Language</th>\n",
       "      <th>Unifying Words Ratio</th>\n",
       "      <th>Polarizing Words Ratio</th>\n",
       "      <th>Overall Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump (2nd Term)</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2905</td>\n",
       "      <td>0</td>\n",
       "      <td>polarizing</td>\n",
       "      <td>0.00723</td>\n",
       "      <td>0.00757</td>\n",
       "      <td>0.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph R. Biden, Jr.</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>2532</td>\n",
       "      <td>1</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.01145</td>\n",
       "      <td>0.00434</td>\n",
       "      <td>2.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald J. Trump (1st Term)</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1455</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00687</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>2.4982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2090</td>\n",
       "      <td>1</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00766</td>\n",
       "      <td>0.00239</td>\n",
       "      <td>3.2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>2391</td>\n",
       "      <td>1</td>\n",
       "      <td>polarizing</td>\n",
       "      <td>0.00627</td>\n",
       "      <td>0.00753</td>\n",
       "      <td>0.8327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2069</td>\n",
       "      <td>0</td>\n",
       "      <td>polarizing</td>\n",
       "      <td>0.00628</td>\n",
       "      <td>0.00628</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>1591</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00880</td>\n",
       "      <td>0.00314</td>\n",
       "      <td>2.8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>William J. Clinton</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2156</td>\n",
       "      <td>1</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.01206</td>\n",
       "      <td>0.00139</td>\n",
       "      <td>8.6763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>William J. Clinton</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1598</td>\n",
       "      <td>1</td>\n",
       "      <td>polarizing</td>\n",
       "      <td>0.00501</td>\n",
       "      <td>0.00563</td>\n",
       "      <td>0.8899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>George Bush</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2320</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00603</td>\n",
       "      <td>0.00086</td>\n",
       "      <td>7.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ronald Reagan</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2561</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00820</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>2.1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ronald Reagan</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>2423</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00660</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jimmy Carter</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1212</td>\n",
       "      <td>1</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.01485</td>\n",
       "      <td>0.00248</td>\n",
       "      <td>5.9879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Richard Nixon</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1833</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00818</td>\n",
       "      <td>0.00109</td>\n",
       "      <td>7.5046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Richard Nixon</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2104</td>\n",
       "      <td>0</td>\n",
       "      <td>unifying</td>\n",
       "      <td>0.00808</td>\n",
       "      <td>0.00238</td>\n",
       "      <td>3.3950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  Unifying Words Count  Polarizing Words Count  \\\n",
       "0   Donald J. Trump (2nd Term)                    21                      22   \n",
       "1         Joseph R. Biden, Jr.                    29                      11   \n",
       "2   Donald J. Trump (1st Term)                    10                       4   \n",
       "3                 Barack Obama                    16                       5   \n",
       "4                 Barack Obama                    15                      18   \n",
       "5               George W. Bush                    13                      13   \n",
       "6               George W. Bush                    14                       5   \n",
       "7           William J. Clinton                    26                       3   \n",
       "8           William J. Clinton                     8                       9   \n",
       "9                  George Bush                    14                       2   \n",
       "10               Ronald Reagan                    21                      10   \n",
       "11               Ronald Reagan                    16                       8   \n",
       "12                Jimmy Carter                    18                       3   \n",
       "13               Richard Nixon                    15                       2   \n",
       "14               Richard Nixon                    17                       5   \n",
       "\n",
       "    Total Words Count  Political Party Overall Language  Unifying Words Ratio  \\\n",
       "0                2905                0       polarizing               0.00723   \n",
       "1                2532                1         unifying               0.01145   \n",
       "2                1455                0         unifying               0.00687   \n",
       "3                2090                1         unifying               0.00766   \n",
       "4                2391                1       polarizing               0.00627   \n",
       "5                2069                0       polarizing               0.00628   \n",
       "6                1591                0         unifying               0.00880   \n",
       "7                2156                1         unifying               0.01206   \n",
       "8                1598                1       polarizing               0.00501   \n",
       "9                2320                0         unifying               0.00603   \n",
       "10               2561                0         unifying               0.00820   \n",
       "11               2423                0         unifying               0.00660   \n",
       "12               1212                1         unifying               0.01485   \n",
       "13               1833                0         unifying               0.00818   \n",
       "14               2104                0         unifying               0.00808   \n",
       "\n",
       "    Polarizing Words Ratio  Overall Ratio  \n",
       "0                  0.00757         0.9551  \n",
       "1                  0.00434         2.6382  \n",
       "2                  0.00275         2.4982  \n",
       "3                  0.00239         3.2050  \n",
       "4                  0.00753         0.8327  \n",
       "5                  0.00628         1.0000  \n",
       "6                  0.00314         2.8025  \n",
       "7                  0.00139         8.6763  \n",
       "8                  0.00563         0.8899  \n",
       "9                  0.00086         7.0116  \n",
       "10                 0.00390         2.1026  \n",
       "11                 0.00330         2.0000  \n",
       "12                 0.00248         5.9879  \n",
       "13                 0.00109         7.5046  \n",
       "14                 0.00238         3.3950  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset first 15 rows of data \n",
    "df3 = df2.head(15).copy()\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Biserial Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.08839\n",
      "p-value: 0.75408\n"
     ]
    }
   ],
   "source": [
    "correlation, p_value = pointbiserialr(df3['Political Party'], df3['Overall Ratio'])\n",
    "\n",
    "print(\"Correlation:\", round(correlation, 5))\n",
    "print(\"p-value:\", round(p_value, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yielded worse results than including all data. Let's try logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Kitchen Sink Model (all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.3333333333333333\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1 1]\n",
      " [1 0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.25      0.25      0.25         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Feature and target selection\n",
    "X = df3.drop(columns=['Political Party', \"Name\", \"Overall Language\"]) # X = df2[[\"Political Party\"]]\n",
    "y = df3['Political Party']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit on train data and transform\n",
    "X_test = scaler.transform(X_test)  # Only transform test data\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "# print(\"Training Accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression also produces strange results with low accuracy. We will focus our analysis on data including all presidential speeches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
